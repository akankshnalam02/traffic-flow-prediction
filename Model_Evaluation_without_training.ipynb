{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1206169d-a771-4a7c-a8bc-902d17747978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model Loaded Successfully ✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████| 325/325 [00:43<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL RESULTS =====\n",
      "Normalized MAE : 0.14823707404772518\n",
      "Normalized RMSE: 0.30634279095634\n",
      "MAPE: 118.81603055029434 %\n",
      "Real MAE : 1.2684547704842077\n",
      "Real RMSE: 2.621354860707189\n",
      "R2 Score: 0.9076744318008423\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# MS-GWN-A ONLY EVALUATION (NO TRAINING)\n",
    "# =============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# =============================================================\n",
    "# LOAD DATA\n",
    "# =============================================================\n",
    "\n",
    "df = pd.read_csv(\"pems_bay_final_with_extra_features.csv\", index_col=\"timestamp\", parse_dates=True)\n",
    "\n",
    "sensor_cols = [c for c in df.columns if c.isdigit()]\n",
    "time_cols = [c for c in df.columns if c not in sensor_cols]\n",
    "\n",
    "traffic = df[sensor_cols].to_numpy(dtype=np.float32)\n",
    "time_feat = df[time_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "mean = traffic.mean(axis=0, keepdims=True)\n",
    "std  = traffic.std(axis=0, keepdims=True)\n",
    "std[std == 0] = 1.0\n",
    "traffic = (traffic - mean) / std\n",
    "\n",
    "T, N = traffic.shape\n",
    "F_time = time_feat.shape[1]\n",
    "\n",
    "traffic = traffic[..., None]\n",
    "time_feat_expanded = np.broadcast_to(time_feat[:, None, :], (T, N, F_time))\n",
    "data = np.concatenate([traffic, time_feat_expanded], axis=2).astype(np.float32)\n",
    "\n",
    "# =============================================================\n",
    "# DATASET\n",
    "# =============================================================\n",
    "\n",
    "SEQ_LEN = 24\n",
    "PRED_LEN = 3\n",
    "\n",
    "class TrafficDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - SEQ_LEN - PRED_LEN\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx : idx+SEQ_LEN]\n",
    "        y = self.data[idx+SEQ_LEN : idx+SEQ_LEN+PRED_LEN, :, 0]\n",
    "        x = torch.from_numpy(x).permute(2,1,0)\n",
    "        y = torch.from_numpy(y)\n",
    "        return x, y\n",
    "\n",
    "split = int(len(data) * 0.8)\n",
    "test_loader = DataLoader(TrafficDataset(data[split:]), batch_size=32, shuffle=False)\n",
    "\n",
    "# =============================================================\n",
    "# ADJACENCY\n",
    "# =============================================================\n",
    "\n",
    "with open(\"adj_mx_PEMS-BAY.pkl\", \"rb\") as f:\n",
    "    adj_data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "A = adj_data[2].astype(np.float32)\n",
    "A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "D = np.sum(A, axis=1)\n",
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(D + 1e-8))\n",
    "A_norm = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "adj_mx = torch.tensor(A_norm, dtype=torch.float32).to(device)\n",
    "\n",
    "# =============================================================\n",
    "# MODEL (EXACT SAME)\n",
    "# =============================================================\n",
    "\n",
    "class NodeAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(channels, channels)\n",
    "        self.key = nn.Linear(channels, channels)\n",
    "        self.value = nn.Linear(channels, channels)\n",
    "        self.scale = math.sqrt(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,N,T = x.shape\n",
    "        x_pool = x.mean(dim=-1).permute(0,2,1)\n",
    "        Q,K,V = self.query(x_pool), self.key(x_pool), self.value(x_pool)\n",
    "        attn = torch.bmm(Q,K.transpose(1,2))/self.scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.bmm(attn,V).permute(0,2,1).unsqueeze(-1).expand(B,C,N,T)\n",
    "        return out\n",
    "\n",
    "class AdaptiveAdjacency(nn.Module):\n",
    "    def __init__(self, num_nodes, adj_fixed):\n",
    "        super().__init__()\n",
    "        self.register_buffer('adj_fixed', adj_fixed)\n",
    "        self.adj_learned = nn.Parameter(torch.randn(num_nodes, num_nodes) * 0.01)\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "    def forward(self):\n",
    "        adj_l = F.relu(self.adj_learned)\n",
    "        adj_l = adj_l/(adj_l.sum(dim=1,keepdim=True)+1e-8)\n",
    "        alpha = torch.sigmoid(self.alpha)\n",
    "        return alpha*self.adj_fixed+(1-alpha)*adj_l\n",
    "\n",
    "class MultiScaleTemporalBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(channels, channels, (1,3), padding=(0,1))\n",
    "        self.conv_2 = nn.Conv2d(channels, channels, (1,3), padding=(0,2), dilation=(1,2))\n",
    "        self.conv_4 = nn.Conv2d(channels, channels, (1,3), padding=(0,4), dilation=(1,4))\n",
    "        self.fusion = nn.Conv2d(channels*3, channels, 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1=F.relu(self.conv_1(x))\n",
    "        x2=F.relu(self.conv_2(x))\n",
    "        x3=F.relu(self.conv_4(x))\n",
    "        return self.fusion(torch.cat([x1,x2,x3],dim=1))\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self,x,adj):\n",
    "        B,C,N,T=x.shape\n",
    "        x=x.permute(0,3,2,1).reshape(B*T,N,C)\n",
    "        x=torch.bmm(adj.unsqueeze(0).expand(B*T,N,N),x)\n",
    "        x=self.lin(x).reshape(B,T,N,-1).permute(0,3,2,1)\n",
    "        return x\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self,pred_len):\n",
    "        super().__init__()\n",
    "        self.attn_weights = nn.Parameter(torch.ones(pred_len)/pred_len)\n",
    "\n",
    "    def forward(self,x):\n",
    "        w=F.softmax(self.attn_weights,dim=0).view(1,-1,1)\n",
    "        return x*w\n",
    "\n",
    "class MS_GWN_A(nn.Module):\n",
    "    def __init__(self,num_nodes,in_dim,out_dim,adj_fixed):\n",
    "        super().__init__()\n",
    "        channels=48\n",
    "        self.adaptive_adj=AdaptiveAdjacency(num_nodes,adj_fixed)\n",
    "        self.input_proj=nn.Conv2d(in_dim,channels,1)\n",
    "        self.temporal_blocks=nn.ModuleList([MultiScaleTemporalBlock(channels) for _ in range(3)])\n",
    "        self.graph_convs=nn.ModuleList([GraphConvolution(channels,channels) for _ in range(3)])\n",
    "        self.node_attentions=nn.ModuleList([NodeAttention(channels) for _ in range(3)])\n",
    "        self.skip_convs=nn.ModuleList([nn.Conv2d(channels,channels,1) for _ in range(3)])\n",
    "        self.temporal_pool=nn.AdaptiveAvgPool2d((num_nodes,1))\n",
    "        self.output_proj=nn.Sequential(nn.Linear(channels,128),nn.ReLU(),nn.Dropout(0.1),nn.Linear(128,out_dim))\n",
    "        self.temporal_attn=TemporalAttention(out_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        adj=self.adaptive_adj()\n",
    "        x=self.input_proj(x)\n",
    "        skips=[]\n",
    "        for t,g,a,s in zip(self.temporal_blocks,self.graph_convs,self.node_attentions,self.skip_convs):\n",
    "            res=x\n",
    "            x=t(x)\n",
    "            x=F.relu(g(x,adj))\n",
    "            x=x+a(x)\n",
    "            x=x+res\n",
    "            skips.append(s(x))\n",
    "        x=torch.stack(skips).sum(0)\n",
    "        x=self.temporal_pool(x).squeeze(-1).permute(0,2,1)\n",
    "        out=self.output_proj(x).permute(0,2,1)\n",
    "        return self.temporal_attn(out)\n",
    "\n",
    "# =============================================================\n",
    "# LOAD MODEL\n",
    "# =============================================================\n",
    "\n",
    "model = MS_GWN_A(num_nodes=N,in_dim=data.shape[2],out_dim=PRED_LEN,adj_fixed=adj_mx).to(device)\n",
    "#model.load_state_dict(torch.load(\"ms_gwn_a_best.pth\",map_location=device))\n",
    "state_dict = torch.load(\"ms_gwn_a_best.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "print(\"Model Loaded Successfully ✓\")\n",
    "\n",
    "# =============================================================\n",
    "# EVALUATE\n",
    "# =============================================================\n",
    "from tqdm import tqdm\n",
    "\n",
    "mae = 0\n",
    "mse = 0\n",
    "mape = 0\n",
    "count = 0\n",
    "\n",
    "preds_list = []\n",
    "trues_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader, desc=\"Evaluating\", ncols=100):\n",
    "\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        # regression metrics\n",
    "        mae += torch.abs(pred - y).sum().item()\n",
    "        mse += ((pred - y) ** 2).sum().item()\n",
    "\n",
    "        mask = y != 0\n",
    "        mape += (torch.abs((pred - y) / (y + 1e-8))[mask]).sum().item()\n",
    "        count += y.numel()\n",
    "\n",
    "        preds_list.append(pred.cpu())\n",
    "        trues_list.append(y.cpu())\n",
    "\n",
    "# stack once at end (memory safe)\n",
    "preds = torch.cat(preds_list).numpy()\n",
    "trues = torch.cat(trues_list).numpy()\n",
    "\n",
    "# metrics\n",
    "mae /= count\n",
    "rmse = (mse / count) ** 0.5\n",
    "mape = (mape / count) * 100\n",
    "\n",
    "real_mae = mae * std.mean()\n",
    "real_rmse = rmse * std.mean()\n",
    "\n",
    "print(\"\\n===== FINAL RESULTS =====\")\n",
    "print(\"Normalized MAE :\", mae)\n",
    "print(\"Normalized RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape, \"%\")\n",
    "print(\"Real MAE :\", real_mae)\n",
    "print(\"Real RMSE:\", real_rmse)\n",
    "\n",
    "# R2\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(trues.reshape(-1), preds.reshape(-1))\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"=========================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed46988f-1d02-475e-9a2b-7f20221cbf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ✓\n",
      "True value at window 9012: 22.20 mph\n"
     ]
    }
   ],
   "source": [
    "# Save normalization + check window\n",
    "np.save(\"train_mean.npy\", mean)\n",
    "np.save(\"train_std.npy\", std)\n",
    "print(\"Saved ✓\")\n",
    "\n",
    "# Check sensor 400863 at window 9012\n",
    "idx = sensor_cols.index('400863')\n",
    "window = 9012\n",
    "\n",
    "true_norm = data[window, idx, 0]\n",
    "true_real = float(true_norm * std[0, idx] + mean[0, idx])\n",
    "print(f\"True value at window 9012: {true_real:.2f} mph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e04d7d1-c9c1-40a6-9551-2dc289c9313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 9012 → Timestamp: 06-02-2017 07:00\n",
      "CSV value at that timestamp: 55.00 mph\n",
      "Data array value:           22.20 mph\n",
      "Match: False\n"
     ]
    }
   ],
   "source": [
    "# Check what timestamp corresponds to window 9012\n",
    "idx = sensor_cols.index('400863')\n",
    "window = 9012\n",
    "\n",
    "# Get the actual timestamp at window 9012\n",
    "df_check = pd.read_csv(\"pems_bay_final_with_extra_features.csv\", \n",
    "                        index_col=\"timestamp\", parse_dates=True)\n",
    "df_check = df_check.sort_index()\n",
    "\n",
    "timestamp = df_check.index[window]\n",
    "csv_value = float(df_check.loc[timestamp, '400863'])\n",
    "\n",
    "print(f\"Window 9012 → Timestamp: {timestamp}\")\n",
    "print(f\"CSV value at that timestamp: {csv_value:.2f} mph\")\n",
    "print(f\"Data array value:           {true_real:.2f} mph\")\n",
    "print(f\"Match: {abs(csv_value - true_real) < 1.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b69d3eaa-33f1-407e-870e-72e4b2b1ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is index monotonic? True\n",
      "Duplicate timestamps: 0\n",
      "Total rows: 52116\n"
     ]
    }
   ],
   "source": [
    "print(\"Is index monotonic?\", df_check.index.is_monotonic_increasing)\n",
    "print(\"Duplicate timestamps:\", df_check.index.duplicated().sum())\n",
    "print(\"Total rows:\", len(df_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "725325ac-0271-41d0-a74a-3c74a2361ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 timestamps: ['01-01-2017 00:00', '01-01-2017 00:05', '01-01-2017 00:10', '01-01-2017 00:15', '01-01-2017 00:20']\n",
      "Timestamp dtype: object\n",
      "Window 9012 timestamp: 06-02-2017 07:00\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 timestamps:\", df_check.index[:5].tolist())\n",
    "print(\"Timestamp dtype:\", df_check.index.dtype)\n",
    "print(\"Window 9012 timestamp:\", df_check.index[9012])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa9b2955-e030-45f4-8b19-aadcd8a9b2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5: [Timestamp('2017-01-01 00:00:00'), Timestamp('2017-01-01 00:05:00'), Timestamp('2017-01-01 00:10:00'), Timestamp('2017-01-01 00:15:00'), Timestamp('2017-01-01 00:20:00')]\n",
      "Window 9012: 2017-02-01 07:00:00\n",
      "CSV value at window 9012: 22.2\n",
      "Data array value: 22.200000762939453\n"
     ]
    }
   ],
   "source": [
    "df_check = pd.read_csv(\"pems_bay_final_with_extra_features.csv\", \n",
    "                        index_col=\"timestamp\")\n",
    "df_check.index = pd.to_datetime(df_check.index, format=\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "print(\"First 5:\", df_check.index[:5].tolist())\n",
    "print(\"Window 9012:\", df_check.index[9012])\n",
    "print(\"CSV value at window 9012:\", df_check.iloc[9012]['400863'])\n",
    "print(\"Data array value:\", true_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa5367-8291-4f47-97e9-6f966c9c88a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
