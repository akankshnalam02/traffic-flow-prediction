{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3d1448-67ad-4fa5-b3f5-58c03cc6b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# üö¶ PEMS-BAY Traffic Forecasting\n",
    "# MODEL: Deep GraphWaveNet (Paper-style STGNN)\n",
    "# =============================================================\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 0Ô∏è‚É£ IMPORTS + DEVICE + STABILITY SETTINGS\n",
    "# =============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Reproducibility (VERY IMPORTANT for projects/research)\n",
    "# -------------------------------------------------------------\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Device\n",
    "# -------------------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# GPU speed boost (safe)\n",
    "# -------------------------------------------------------------\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d110bb-7c85-4233-9c2d-f2ae4fc415e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Path: C:\\Users\\akanksh_02\\Downloads\\trf\\pems_bay_final_with_extra_features.csv\n",
      "Adj Path: C:\\Users\\akanksh_02\\Downloads\\trf\\adj_mx_PEMS-BAY.pkl\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 1Ô∏è‚É£ PATHS (SAFE + PORTABLE VERSION)\n",
    "# =============================================================\n",
    "import os\n",
    "\n",
    "BASE_DIR = os.getcwd()   # current working directory\n",
    "\n",
    "csv_path = os.path.join(BASE_DIR, \"pems_bay_final_with_extra_features.csv\")\n",
    "adj_path = os.path.join(BASE_DIR, \"adj_mx_PEMS-BAY.pkl\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Safety check (prevents silent file errors)\n",
    "# -------------------------------------------------------------\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"CSV not found: {csv_path}\")\n",
    "\n",
    "if not os.path.exists(adj_path):\n",
    "    raise FileNotFoundError(f\"Adjacency file not found: {adj_path}\")\n",
    "\n",
    "\n",
    "print(\"CSV Path:\", csv_path)\n",
    "print(\"Adj Path:\", adj_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8353349-c23a-4eab-83d4-c62e33b284d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading CSV...\n",
      "Dataset shape: (52116, 338)\n",
      "Columns: 338\n",
      "Memory optimized ‚úì\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 2Ô∏è‚É£ LOAD CSV (MEMORY OPTIMIZED)\n",
    "# =============================================================\n",
    "print(\"\\nüìÇ Loading CSV...\")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    index_col=\"timestamp\",\n",
    "    parse_dates=True,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", len(df.columns))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert numeric columns ‚Üí float32 (50% memory reduction)\n",
    "# -------------------------------------------------------------\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"float64\":\n",
    "        df[col] = df[col].astype(\"float32\")\n",
    "\n",
    "print(\"Memory optimized ‚úì\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab32cd29-8239-42c4-a8d8-441149a8f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Selecting sensor + time features...\n",
      "Number of sensors (nodes): 325\n",
      "Traffic shape     : (52116, 325)\n",
      "Time feat shape   : (52116, 6)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 3Ô∏è‚É£ SELECT COLUMNS (SAFE + MEMORY OPTIMIZED)\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüß© Selecting sensor + time features...\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Sensor columns (graph nodes)\n",
    "# -------------------------------------------------------------\n",
    "sensor_cols = [c for c in df.columns if c.isdigit()]\n",
    "\n",
    "if len(sensor_cols) == 0:\n",
    "    raise ValueError(\"No sensor columns detected!\")\n",
    "\n",
    "print(\"Number of sensors (nodes):\", len(sensor_cols))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Time features (extra node features)\n",
    "# -------------------------------------------------------------\n",
    "time_cols = [\n",
    "    \"hour_sin\", \"hour_cos\",\n",
    "    \"dow_sin\", \"dow_cos\",\n",
    "    \"weekend\", \"holiday\"\n",
    "]\n",
    "\n",
    "for c in time_cols:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing time feature column: {c}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert to numpy float32 (IMPORTANT)\n",
    "# -------------------------------------------------------------\n",
    "traffic = df[sensor_cols].to_numpy(dtype=np.float32)\n",
    "time_feat = df[time_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "\n",
    "print(\"Traffic shape     :\", traffic.shape)   # (T, N)\n",
    "print(\"Time feat shape   :\", time_feat.shape) # (T, F_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b641c732-e033-4a02-a888-054fd13c266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Normalizing traffic per sensor...\n",
      "Normalized ‚úì\n",
      "Mean shape: (1, 325)\n",
      "Std shape : (1, 325)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 4Ô∏è‚É£ NORMALIZE TRAFFIC (PER-SENSOR NORMALIZATION ‚≠ê)\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüìä Normalizing traffic per sensor...\")\n",
    "\n",
    "# compute mean/std for EACH sensor (column-wise)\n",
    "mean = traffic.mean(axis=0, keepdims=True)\n",
    "std  = traffic.std(axis=0, keepdims=True)\n",
    "\n",
    "# avoid divide by zero\n",
    "std[std == 0] = 1.0\n",
    "\n",
    "traffic = (traffic - mean) / std\n",
    "\n",
    "traffic = traffic.astype(np.float32)\n",
    "\n",
    "print(\"Normalized ‚úì\")\n",
    "print(\"Mean shape:\", mean.shape)  # (1, N)\n",
    "print(\"Std shape :\", std.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fae01bf-5a1a-4abd-a4bf-277a5edea93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üï∏ Loading adjacency...\n",
      "Raw adjacency: (325, 325)\n",
      "Normalized adjacency shape: torch.Size([325, 325])\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 5Ô∏è‚É£ LOAD + NORMALIZE ADJACENCY (RESEARCH STANDARD ‚≠ê)\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüï∏ Loading adjacency...\")\n",
    "\n",
    "with open(adj_path, \"rb\") as f:\n",
    "    adj_data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "A = adj_data[2].astype(np.float32)\n",
    "\n",
    "print(\"Raw adjacency:\", A.shape)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Add self-loops\n",
    "# -------------------------------------------------------------\n",
    "A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Symmetric normalization: D^-1/2 A D^-1/2\n",
    "# -------------------------------------------------------------\n",
    "D = np.sum(A, axis=1)\n",
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(D + 1e-8))\n",
    "\n",
    "A_norm = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert to torch\n",
    "# -------------------------------------------------------------\n",
    "adj_mx = torch.tensor(A_norm, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Normalized adjacency shape:\", adj_mx.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dafbc2e3-3b78-4089-94b4-ae51227f0562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó Combining traffic + time features...\n",
      "Time steps (T): 52116\n",
      "Nodes (N): 325\n",
      "Features per node: 7\n",
      "Final data shape: (52116, 325, 7)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 6Ô∏è‚É£ ADD TIME FEATURES TO EVERY NODE (MEMORY SAFE ‚≠ê)\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüîó Combining traffic + time features...\")\n",
    "\n",
    "T, N = traffic.shape\n",
    "F_time = time_feat.shape[1]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Expand dims safely (no heavy copy)\n",
    "# -------------------------------------------------------------\n",
    "traffic = traffic[..., None]          # (T, N, 1)\n",
    "\n",
    "# broadcast instead of repeat (VERY IMPORTANT)\n",
    "time_feat_expanded = np.broadcast_to(\n",
    "    time_feat[:, None, :],            # (T,1,F_time)\n",
    "    (T, N, F_time)                   # (T,N,F_time)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Concatenate features\n",
    "# -------------------------------------------------------------\n",
    "data = np.concatenate(\n",
    "    [traffic, time_feat_expanded],\n",
    "    axis=2\n",
    ").astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"Time steps (T):\", T)\n",
    "print(\"Nodes (N):\", N)\n",
    "print(\"Features per node:\", data.shape[2])\n",
    "print(\"Final data shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e22403d-ea09-4a44-b1fb-506ba2a5a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# 7Ô∏è‚É£ MEMORY SAFE DATASET (PROFESSIONAL VERSION ‚≠ê)\n",
    "# =============================================================\n",
    "\n",
    "SEQ_LEN = 24\n",
    "PRED_LEN = 3\n",
    "\n",
    "\n",
    "class TrafficDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        # ‚≠ê keep as numpy (NO big torch copy)\n",
    "        self.data = data.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - SEQ_LEN - PRED_LEN\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # -----------------------------------------------------\n",
    "        # slice windows (numpy)\n",
    "        # -----------------------------------------------------\n",
    "        x = self.data[idx : idx+SEQ_LEN]                 # (T,N,F)\n",
    "        y = self.data[idx+SEQ_LEN : idx+SEQ_LEN+PRED_LEN, :, 0]  # (P,N)\n",
    "\n",
    "        # -----------------------------------------------------\n",
    "        # convert ONLY this sample to torch (fast)\n",
    "        # -----------------------------------------------------\n",
    "        x = torch.from_numpy(x).permute(2,1,0)  # (F,N,T)\n",
    "        y = torch.from_numpy(y)\n",
    "\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca03398d-661c-4afa-bd4a-619d20a05059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Creating train/test split...\n",
      "Train samples: 41692\n",
      "Test samples : 10424\n",
      "Batches per epoch: 651\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 8Ô∏è‚É£ TRAIN / TEST SPLIT + DATALOADER (FINAL SAFE VERSION ‚≠ê)\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüì¶ Creating train/test split...\")\n",
    "\n",
    "split = int(len(data) * 0.8)\n",
    "\n",
    "train_data = data[:split]\n",
    "test_data  = data[split:]\n",
    "\n",
    "print(\"Train samples:\", len(train_data))\n",
    "print(\"Test samples :\", len(test_data))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Windows + CUDA safe loaders\n",
    "# -------------------------------------------------------------\n",
    "train_loader = DataLoader(\n",
    "    TrafficDataset(train_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,      # ‚≠ê Windows safe\n",
    "    pin_memory=True,    # ‚≠ê faster GPU transfer\n",
    "    drop_last=True      # ‚≠ê stable batches\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TrafficDataset(test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Batches per epoch:\", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baedc84c-937c-44b1-8839-2cafea287d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# STEP 2Ô∏è‚É£  MTGNN MODEL (ONLY REPLACE MODEL PART)\n",
    "# =============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MTGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    MTGNN ‚Äì Multivariate Time-series Graph Neural Network\n",
    "    Paper: Connecting the Dots (2020)\n",
    "\n",
    "    Key ideas:\n",
    "    - Adaptive Graph Learning\n",
    "    - Temporal CNN (no GRU)\n",
    "    - Mix-hop Graph Convolution\n",
    "    - Gated blocks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_nodes, in_dim, out_dim, seq_len):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        channels = 64\n",
    "        layers = 6\n",
    "\n",
    "        # =====================================================\n",
    "        # ‚≠ê Adaptive graph learning (MOST IMPORTANT PART)\n",
    "        # Learns graph automatically (beats fixed adjacency)\n",
    "        # =====================================================\n",
    "        self.nodevec1 = nn.Parameter(torch.randn(num_nodes, 10))\n",
    "        self.nodevec2 = nn.Parameter(torch.randn(10, num_nodes))\n",
    "\n",
    "\n",
    "        # =====================================================\n",
    "        # Input projection\n",
    "        # =====================================================\n",
    "        self.start_conv = nn.Conv2d(in_dim, channels, kernel_size=(1,1))\n",
    "\n",
    "\n",
    "        # =====================================================\n",
    "        # Temporal + Graph blocks\n",
    "        # =====================================================\n",
    "        self.temporal_convs = nn.ModuleList()\n",
    "        self.graph_convs = nn.ModuleList()\n",
    "\n",
    "        for _ in range(layers):\n",
    "\n",
    "            # Temporal CNN\n",
    "            self.temporal_convs.append(\n",
    "                nn.Conv2d(\n",
    "                    channels,\n",
    "                    channels,\n",
    "                    kernel_size=(1,3),\n",
    "                    padding=(0,1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Graph mixing\n",
    "            self.graph_convs.append(\n",
    "                nn.Linear(num_nodes, num_nodes, bias=False)\n",
    "            )\n",
    "\n",
    "\n",
    "        # =====================================================\n",
    "        # Output head\n",
    "        # =====================================================\n",
    "        self.end_conv = nn.Conv2d(channels, out_dim, kernel_size=(1,1))\n",
    "\n",
    "\n",
    "    # =========================================================\n",
    "    # Adaptive graph creation\n",
    "    # =========================================================\n",
    "    def get_adj(self):\n",
    "        adj = F.relu(torch.mm(self.nodevec1, self.nodevec2))\n",
    "        adj = F.softmax(adj, dim=1)\n",
    "        return adj\n",
    "\n",
    "\n",
    "    # =========================================================\n",
    "    # Forward\n",
    "    # =========================================================\n",
    "    def forward(self, x):\n",
    "\n",
    "        adj = self.get_adj()\n",
    "\n",
    "        x = self.start_conv(x)\n",
    "\n",
    "        for tconv, gconv in zip(self.temporal_convs, self.graph_convs):\n",
    "\n",
    "            residual = x\n",
    "\n",
    "            # temporal\n",
    "            x = F.relu(tconv(x))\n",
    "\n",
    "            # graph\n",
    "            x = torch.einsum(\"bfnt,nm->bfmt\", x, adj)\n",
    "\n",
    "            x = x + residual\n",
    "\n",
    "        x = self.end_conv(x)\n",
    "\n",
    "        return x.mean(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a37fcad-949a-4fac-ad3a-b823d68abbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Initializing MTGNN model...\n",
      "Input features : 7\n",
      "Nodes          : 325\n",
      "Seq length     : 24\n",
      "Prediction     : 3\n",
      "Parameters     : 0.72 M\n",
      "Device         : cuda\n",
      "MTGNN ready ‚úì\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# STEP 3Ô∏è‚É£  MTGNN INITIALIZATION\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüß† Initializing MTGNN model...\")\n",
    "\n",
    "model = MTGNN(\n",
    "    num_nodes=N,            # 325 sensors\n",
    "    in_dim=data.shape[2],   # 7 features\n",
    "    out_dim=PRED_LEN,       # predict 3 steps\n",
    "    seq_len=SEQ_LEN         # 24 history\n",
    ").to(device)\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(\"Input features :\", data.shape[2])\n",
    "print(\"Nodes          :\", N)\n",
    "print(\"Seq length     :\", SEQ_LEN)\n",
    "print(\"Prediction     :\", PRED_LEN)\n",
    "print(\"Parameters     :\", round(total_params/1e6, 2), \"M\")\n",
    "print(\"Device         :\", device)\n",
    "print(\"MTGNN ready ‚úì\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade7d10b-0d0a-44cd-be04-710125ace059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training MTGNN...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:34<00:00,  3.04it/s, loss=0.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 1/25  Loss: 0.3360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:33<00:00,  3.05it/s, loss=0.682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 2/25  Loss: 0.2837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:33<00:00,  3.05it/s, loss=0.569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 3/25  Loss: 0.2673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:34<00:00,  3.05it/s, loss=0.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 4/25  Loss: 0.2599\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:37<00:00,  3.00it/s, loss=0.326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 5/25  Loss: 0.2530\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:41<00:00,  2.95it/s, loss=0.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 6/25  Loss: 0.2453\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:34<00:00,  3.05it/s, loss=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 7/25  Loss: 0.2391\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:41<00:00,  2.95it/s, loss=0.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 8/25  Loss: 0.2341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:44<00:00,  2.90it/s, loss=0.154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 9/25  Loss: 0.2339\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:41<00:00,  2.94it/s, loss=0.0993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 10/25  Loss: 0.2221\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:45<00:00,  2.89it/s, loss=0.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 11/25  Loss: 0.2161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:40<00:00,  2.95it/s, loss=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 12/25  Loss: 0.2075\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:41<00:00,  2.95it/s, loss=0.308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 13/25  Loss: 0.2016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:49<00:00,  2.84it/s, loss=0.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 14/25  Loss: 0.1970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:49<00:00,  2.85it/s, loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 15/25  Loss: 0.1916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:50<00:00,  2.83it/s, loss=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 16/25  Loss: 0.1886\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:48<00:00,  2.85it/s, loss=0.118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 17/25  Loss: 0.1873\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:49<00:00,  2.84it/s, loss=0.283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 18/25  Loss: 0.1855\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:53<00:00,  2.79it/s, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 19/25  Loss: 0.1818\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:52<00:00,  2.80it/s, loss=0.216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 20/25  Loss: 0.1788\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:48<00:00,  2.85it/s, loss=0.0903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 21/25  Loss: 0.1773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:52<00:00,  2.80it/s, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 22/25  Loss: 0.1749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:48<00:00,  2.85it/s, loss=0.315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 23/25  Loss: 0.1736\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:48<00:00,  2.85it/s, loss=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 24/25  Loss: 0.1723\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [03:53<00:00,  2.79it/s, loss=0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Epoch 25/25  Loss: 0.1709\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# STEP 4Ô∏è‚É£  MTGNN TRAINING LOOP (FAST + STABLE)\n",
    "# =============================================================\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.L1Loss()          # MAE (best for traffic)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "EPOCHS = 25\n",
    "\n",
    "\n",
    "# ‚≠ê MTGNN can use larger batch (faster than GraphWaveNet)\n",
    "train_loader = DataLoader(\n",
    "    TrafficDataset(train_data),\n",
    "    batch_size=64,          # bigger batch ‚Üí faster GPU\n",
    "    shuffle=True,\n",
    "    num_workers=0,          # Windows safe\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nüöÄ Training MTGNN...\\n\")\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for x, y in pbar:\n",
    "\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)  # ‚≠ê stability\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "    print(f\"‚úÖ Epoch {epoch+1}/{EPOCHS}  Loss: {epoch_loss/len(train_loader):.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54561a39-26f2-4b7e-886d-8e57d289bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluating MTGNN on test set...\n",
      "\n",
      "===================================\n",
      "Normalized MAE : 0.1784\n",
      "Normalized RMSE: 0.3884\n",
      "-----------------------------------\n",
      "Real MAE : 1.526\n",
      "Real RMSE: 3.323\n",
      "R¬≤ score : 0.8516\n",
      "===================================\n",
      "Model saved ‚úì\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# FINAL EVALUATION ‚Äî MTGNN ONLY (FIXED VERSION)\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüìä Evaluating MTGNN on test set...\\n\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "mae_sum = 0.0\n",
    "mse_sum = 0.0\n",
    "count = 0\n",
    "\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for x, y in test_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        error = pred - y\n",
    "\n",
    "        mae_sum += torch.abs(error).sum().item()\n",
    "        mse_sum += (error ** 2).sum().item()\n",
    "        count += y.numel()\n",
    "\n",
    "        all_preds.append(pred.detach().cpu())\n",
    "        all_true.append(y.detach().cpu())\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# Normalized metrics\n",
    "# =============================================================\n",
    "mae_norm = mae_sum / count\n",
    "rmse_norm = (mse_sum / count) ** 0.5\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# Convert back to REAL scale (FIXED HERE)\n",
    "# =============================================================\n",
    "std_scalar = float(np.mean(std))   # ‚≠ê FIX: convert to scalar\n",
    "\n",
    "real_mae = mae_norm * std_scalar\n",
    "real_rmse = rmse_norm * std_scalar\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# R¬≤ score\n",
    "# =============================================================\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "preds = torch.cat(all_preds).numpy().ravel()\n",
    "trues = torch.cat(all_true).numpy().ravel()\n",
    "\n",
    "r2 = r2_score(trues, preds)\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# Print results\n",
    "# =============================================================\n",
    "print(\"===================================\")\n",
    "print(f\"Normalized MAE : {mae_norm:.4f}\")\n",
    "print(f\"Normalized RMSE: {rmse_norm:.4f}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Real MAE : {real_mae:.3f}\")\n",
    "print(f\"Real RMSE: {real_rmse:.3f}\")\n",
    "print(f\"R¬≤ score : {r2:.4f}\")\n",
    "print(\"===================================\")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# Save model\n",
    "# =============================================================\n",
    "torch.save(model.state_dict(), \"mtgnn_model.pth\")\n",
    "print(\"Model saved ‚úì\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4098d-98b0-4374-a63f-e3ba66c73282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
